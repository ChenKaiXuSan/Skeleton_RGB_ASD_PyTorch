#!/usr/bin/env python3
# -*- coding:utf-8 -*-
"""
File: /workspace/code/sam3d_body/sam3d.py
Project: /workspace/code/sam3d_body
Created Date: Thursday December 4th 2025
Author: Kaixu Chen
-----
Comment:
å…ˆæ¨ç†SAM-3D-Bodyæ¨¡å‹ï¼Œç„¶åæ ¹æ®é¢ç§¯æœ€å¤§çš„ bbox é€‰å‡ºä¸»è¦äººç‰©è¿›è¡Œå¯è§†åŒ–å’Œä¿å­˜

Have a good code time :)
-----
Last Modified: Thursday December 4th 2025 4:24:51 pm
Modified By: the developer formerly known as Kaixu Chen at <chenkaixusan@gmail.com>
-----
Copyright (c) 2025 The University of Tsukuba
-----
HISTORY:
Date      	By	Comments
----------	---	---------------------------------------------------------
"""

import logging
import os
from pathlib import Path
import numpy as np

import torch
from omegaconf.omegaconf import DictConfig
from tqdm import tqdm

from .sam_3d_body import SAM3DBodyEstimator, load_sam_3d_body
from .sam_3d_body.metadata.mhr70 import pose_info as mhr70_pose_info
from .sam_3d_body.visualization.skeleton_visualizer import SkeletonVisualizer
from .save import save_frame
from .vis import (
    vis_results,
)

logger = logging.getLogger(__name__)


# å®šä¹‰ä¸€ä¸ªè®¡ç®—é¢ç§¯çš„å‡½æ•°ï¼ˆåŸºäº bbox: [x1, y1, x2, y2]ï¼‰
def select_best_person(outputs, verbose=True):
    """
    ä»å¤šä¸ªæ£€æµ‹ç»“æœä¸­é€‰å‡ºé¢ç§¯æœ€å¤§ï¼ˆç½®ä¿¡åº¦æœ€é«˜ï¼‰çš„ä¸€ä¸ªã€‚

    Args:
        outputs (list): æ¨¡å‹è¾“å‡ºçš„ dict åˆ—è¡¨.
        verbose (bool): æ˜¯å¦æ‰“å°æ¯ä¸ªæ£€æµ‹æ¡†çš„ä¿¡æ¯ã€‚

    Returns:
        tuple: (best_target, best_idx) å¦‚æœæ²¡æœ‰ç»“æœåˆ™è¿”å› (None, None)
    """
    if not outputs:
        if verbose:
            print("âš ï¸ æœªæ£€æµ‹åˆ°ä»»ä½•ç›®æ ‡ã€‚")
        return None, None

    areas = []
    for i, obj in enumerate(outputs):
        # è·å– bbox åæ ‡ [x1, y1, x2, y2]
        bbox = obj.get("bbox", [0, 0, 0, 0])

        # è®¡ç®—é¢ç§¯
        width = bbox[2] - bbox[0]
        height = bbox[3] - bbox[1]
        area = width * height
        areas.append(area)

        if verbose:
            print(
                f"æ£€æµ‹åˆ°åºå· [{i}]: é¢ç§¯ = {area:10.2f} | BBox = [{int(bbox[0])}, {int(bbox[1])}, {int(bbox[2])}, {int(bbox[3])}]"
            )

    # æ‰¾åˆ°é¢ç§¯æœ€å¤§çš„ç´¢å¼•
    best_idx = np.argmax(areas)
    best_target = outputs[best_idx]

    if verbose:
        print(f"ğŸ† æœ€ç»ˆé€‰å®š: {best_idx} å· (é¢ç§¯: {areas[best_idx]:.2f})")
        print("-" * 50)

    return best_target, best_idx


def setup_visualizer():
    """Set up skeleton visualizer with MHR70 pose info"""
    visualizer = SkeletonVisualizer(line_width=2, radius=5)
    visualizer.set_pose_meta(mhr70_pose_info)
    return visualizer


def setup_sam_3d_body(
    cfg: DictConfig,
):
    # å¦‚æœå‚æ•°ä¸ºç©ºï¼Œåˆ™ä»ç¯å¢ƒå˜é‡ä¸­è¯»å–
    mhr_path = cfg.model.get("mhr_path", "") or os.environ.get("SAM3D_MHR_PATH", "")
    # helper params
    detector_name = cfg.model.get("detector_name", "vitdet")
    segmentor_name = cfg.model.get("segmentor_name", "")
    fov_name = cfg.model.get("fov_name", "moge2")
    detector_path = cfg.model.get("detector_path", "") or os.environ.get(
        "SAM3D_DETECTOR_PATH", ""
    )
    segmentor_path = cfg.model.get("segmentor_path", "") or os.environ.get(
        "SAM3D_SEGMENTOR_PATH", ""
    )
    fov_path = cfg.model.get("fov_path", "") or os.environ.get("SAM3D_FOV_PATH", "")

    # -------------------- åˆå§‹åŒ–ä¸»æ¨¡å‹ -------------------- #
    sam3d_model, model_cfg = load_sam_3d_body(
        cfg.model.checkpoint_path,
        device=cfg.infer.gpu,
        mhr_path=mhr_path,
    )

    # -------------------- å¯é€‰æ¨¡å—ï¼šdetector / segmentor / fov -------------------- #
    human_detector = None
    human_segmentor = None
    fov_estimator = None

    if detector_name:
        from .tools.build_detector import HumanDetector

        human_detector = HumanDetector(
            name=detector_name,
            device=cfg.infer.gpu,
            path=detector_path,
        )

    if segmentor_name:
        from .tools.build_sam import HumanSegmentor

        human_segmentor = HumanSegmentor(
            name=segmentor_name,
            device=cfg.infer.gpu,
            path=segmentor_path,
        )

    if fov_name:
        from .tools.build_fov_estimator import FOVEstimator

        fov_estimator = FOVEstimator(
            name=fov_name,
            device=cfg.infer.gpu,
            path=fov_path,
        )

    # æŒ‚åˆ°æˆå‘˜å˜é‡ä¸Š
    estimator = SAM3DBodyEstimator(
        sam_3d_body_model=sam3d_model,
        model_cfg=model_cfg,
        human_detector=human_detector,
        human_segmentor=human_segmentor,
        fov_estimator=fov_estimator,
    )

    logger.info("==== SAM 3D Body Estimator Setup ====")
    logger.info(f"  Model checkpoint: {cfg.model.checkpoint_path}")
    logger.info(f"  MHR model path: {mhr_path if mhr_path else 'Default'}")
    logger.info(
        f"  Human detector: {'âœ“' if human_detector else 'âœ— (will use full image or manual bbox)'}"
    )
    logger.info(
        f"  Human segmentor: {'âœ“' if human_segmentor else 'âœ— (mask inference disabled)'}"
    )
    logger.info(
        f"  FOV estimator: {'âœ“' if fov_estimator else 'âœ— (will use default FOV)'}"
    )
    return estimator


# ------------------------------------------------------------------ #
# é«˜çº§æ¥å£ï¼ˆå¤„ç†æ–‡ä»¶å¤¹ç­‰ï¼‰
# ------------------------------------------------------------------ #
def process_frame_list(
    frame_list: list,
    out_dir: Path,
    inference_output_path: Path,
    start_mid_end_dict: dict,
    cfg: DictConfig,
):
    """å¤„ç†å•ä¸ªè§†é¢‘æ–‡ä»¶çš„é•œå¤´ç¼–è¾‘ã€‚"""

    out_dir.mkdir(parents=True, exist_ok=True)
    inference_output_path.mkdir(parents=True, exist_ok=True)

    # åˆå§‹åŒ–æ¨¡å‹ä¸å¯è§†åŒ–å™¨
    estimator = setup_sam_3d_body(cfg)
    visualizer = setup_visualizer()

    # * æ ¹æ® start_mid_end_dict ä¸­çš„start midä¿¡æ¯è¿›è¡Œåˆ‡æ–­frame_list
    if start_mid_end_dict:
        start = start_mid_end_dict["start"]
        mid = start_mid_end_dict["mid"]
        end = start_mid_end_dict["end"]

        # ç¬¬ä¸€é˜¶æ®µï¼šåªæ¨ç† start åˆ° mid çš„éƒ¨åˆ†ï¼Œ ä»¥èŠ‚çœæ—¶é—´
        # end = mid
        # ç¬¬äºŒé˜¶æ®µï¼šåªæ¨ç† mid-end çš„éƒ¨åˆ†ï¼Œ ä»¥èŠ‚çœæ—¶é—´
        start = mid

        logger.info(
            f"  æ ¹æ® star, mid ä¿¡æ¯å¤„ç†å¸§æ•°æ®: start={start}, mid={mid}, æ€»å¤„ç†={end - start} å¸§ã€‚"
        )
    else:
        start = 0
        end = len(frame_list)

    # sam3d bodyæ£€æµ‹ä¸å‡ºæ¥äººçš„æ—¶å€™è®°å½•ä¸€ä¸‹
    none_detected_frames = []

    # è¿™é‡Œéœ€è¦ä¿æŒå¸§å·
    # for idx in tqdm(range(len(frame_list)), desc="Processing frames"):
    for idx in tqdm(range(start, end), desc="Processing frames"):
        # if idx > 1:
        #     break

        outputs = estimator.process_one_image(
            img=frame_list[idx],
            bboxes=None,
        )

        # åœ¨å¤„ç† outputs æ—¶è¿›è¡Œç­›é€‰ï¼Œ é€‰å‡ºé¢ç§¯æœ€å¤§çš„é‚£ä¸ªäºº
        # è¾“å‡ºæœ€å¤§é¢ç§¯çš„ä¿¡æ¯
        best_person, best_id = select_best_person(outputs)

        if best_person is None:
            logger.warning(f"[Skip] No person detected in frame {idx}.")
            none_detected_frames.append(idx)
            continue

        # å¯è§†åŒ–å¹¶ä¿å­˜ç»“æœ
        vis_results(
            img_cv2=frame_list[idx],
            outputs=[best_person],
            save_dir=str(out_dir / "visualization" / f"frame_{idx:04d}"),
            image_name=f"frame_{idx:04d}",
            faces=estimator.faces,
            visualizer=visualizer,
            cfg=cfg.visualize,
        )

        outputs = best_person
        outputs["frame"] = frame_list[idx]
        outputs["frame_idx"] = idx

        save_frame(
            output=outputs,
            save_dir=inference_output_path,
            frame_idx=outputs["frame_idx"],
        )

    # final
    torch.cuda.empty_cache()
    del estimator
    del visualizer

    # ä¿å­˜æœªæ£€æµ‹åˆ°äººçš„å¸§å·
    if none_detected_frames:
        none_detected_frames_file = inference_output_path / "none_detected_frames.txt"
        with open(none_detected_frames_file, "w") as f:
            for frame_idx in none_detected_frames:
                f.write(f"{frame_idx}\n")
        logger.info(
            f"âš ï¸ å…± {len(none_detected_frames)} å¸§æœªæ£€æµ‹åˆ°äººç‰©ï¼Œå·²ä¿å­˜è‡³ {none_detected_frames_file}"
        )

    return out_dir
